{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e050061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Clean Submission File Generators for All Subtasks\n",
    "This script takes the prediction files with extra columns and creates clean submission files\n",
    "\"\"\"\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "# Set your language\n",
    "LANGUAGE = 'eng'  # Change to 'swa' or 'amh' as needed\n",
    "\n",
    "# Set which model's predictions to use (short name from training)\n",
    "# Examples: 'twitter-roberta-base-hate-latest', 'deberta-v3-base', 'xlm-roberta-base', 'afro-xlmr-base'\n",
    "MODEL_NAME = 'deberta-v3-base'\n",
    "\n",
    "# ==================== SUBTASK 1: BINARY CLASSIFICATION ====================\n",
    "def create_subtask1_submission(language, model_name):\n",
    "    \"\"\"\n",
    "    Create clean submission for Subtask 1 (Binary: polarization)\n",
    "    Expected format: id, polarization\n",
    "    \"\"\"\n",
    "    input_file = f'./subtask1/predictions_{language}_{model_name}.csv'\n",
    "    output_file = f'./submission/submission_subtask1_{language}_{model_name}.csv'\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: {input_file} not found!\")\n",
    "        return\n",
    "    \n",
    "    # Read predictions\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Create clean submission with only required columns\n",
    "    submission = pd.DataFrame()\n",
    "    \n",
    "    # ID column\n",
    "    if 'id' in df.columns:\n",
    "        submission['id'] = df['id']\n",
    "    else:\n",
    "        print(\"Warning: No 'id' column found!\")\n",
    "        return\n",
    "    \n",
    "    # Use per-label threshold predictions (best performance)\n",
    "    if 'polarization_tuned' in df.columns:\n",
    "        submission['polarization'] = df['polarization_tuned']\n",
    "    elif 'polarization' in df.columns:\n",
    "        submission['polarization'] = df['polarization']\n",
    "    else:\n",
    "        print(\"Error: No polarization column found!\")\n",
    "        return\n",
    "    \n",
    "    # Save\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"Subtask 1: Created {output_file}\")\n",
    "    print(f\"  Columns: {submission.columns.tolist()}\")\n",
    "    print(f\"  Rows: {len(submission)}\")\n",
    "    print(f\"  Sample:\\n{submission.head()}\\n\")\n",
    "\n",
    "# ==================== SUBTASK 2: MULTI-LABEL POLARIZATION ====================\n",
    "def create_subtask2_submission(language, model_name):\n",
    "    \"\"\"\n",
    "    Create clean submission for Subtask 2 (Multi-label: 5 polarization types)\n",
    "    Expected format: id, gender/sexual, political, religious, racial/ethnic, other\n",
    "    \"\"\"\n",
    "    input_file = f'./subtask2/predictions_{language}_{model_name}.csv'\n",
    "    output_file = f'./submission/submission_subtask2_{language}_{model_name}.csv'\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: {input_file} not found!\")\n",
    "        return\n",
    "    \n",
    "    # Read predictions\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Define label columns\n",
    "    label_columns = ['gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
    "    \n",
    "    # Create clean submission\n",
    "    submission = pd.DataFrame()\n",
    "    \n",
    "    # ID column\n",
    "    if 'id' in df.columns:\n",
    "        submission['id'] = df['id']\n",
    "    else:\n",
    "        print(\"Warning: No 'id' column found!\")\n",
    "        return\n",
    "    \n",
    "    # Add label columns (use per-label threshold predictions - best performance)\n",
    "    for label in label_columns:\n",
    "        if label in df.columns:\n",
    "            # This is the per-label threshold prediction (recommended)\n",
    "            submission[label] = df[label].astype(int)\n",
    "        elif f'{label}_default' in df.columns:\n",
    "            # Fallback to default if per-label not available\n",
    "            submission[label] = df[f'{label}_default'].astype(int)\n",
    "        else:\n",
    "            print(f\"Error: Column {label} not found!\")\n",
    "            return\n",
    "    \n",
    "    # Save\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"Subtask 2: Created {output_file}\")\n",
    "    print(f\"  Columns: {submission.columns.tolist()}\")\n",
    "    print(f\"  Rows: {len(submission)}\")\n",
    "    print(f\"  Sample:\\n{submission.head()}\\n\")\n",
    "\n",
    "# ==================== SUBTASK 3: MULTI-LABEL MANIFESTATION ====================\n",
    "def create_subtask3_submission(language, model_name):\n",
    "    \"\"\"\n",
    "    Create clean submission for Subtask 3 (Multi-label: 6 manifestation types)\n",
    "    Expected format: id, stereotype, vilification, dehumanization, extreme_language, lack_of_empathy, invalidation\n",
    "    \"\"\"\n",
    "    input_file = f'./subtask3/predictions_{language}_{model_name}.csv'\n",
    "    output_file = f'./submission/submission_subtask3_{language}_{model_name}.csv'\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: {input_file} not found!\")\n",
    "        return\n",
    "    \n",
    "    # Read predictions\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Define label columns\n",
    "    label_columns = ['stereotype', 'vilification', 'dehumanization', \n",
    "                     'extreme_language', 'lack_of_empathy', 'invalidation']\n",
    "    \n",
    "    # Create clean submission\n",
    "    submission = pd.DataFrame()\n",
    "    \n",
    "    # ID column\n",
    "    if 'id' in df.columns:\n",
    "        submission['id'] = df['id']\n",
    "    else:\n",
    "        print(\"Warning: No 'id' column found!\")\n",
    "        return\n",
    "    \n",
    "    # Add label columns (use per-label threshold predictions - best performance)\n",
    "    for label in label_columns:\n",
    "        if label in df.columns:\n",
    "            # This is the per-label threshold prediction (recommended)\n",
    "            submission[label] = df[label].astype(int)\n",
    "        elif f'{label}_default' in df.columns:\n",
    "            # Fallback to default if per-label not available\n",
    "            submission[label] = df[f'{label}_default'].astype(int)\n",
    "        else:\n",
    "            print(f\"Error: Column {label} not found!\")\n",
    "            return\n",
    "    \n",
    "    # Save\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"Subtask 3: Created {output_file}\")\n",
    "    print(f\"  Columns: {submission.columns.tolist()}\")\n",
    "    print(f\"  Rows: {len(submission)}\")\n",
    "    print(f\"  Sample:\\n{submission.head()}\\n\")\n",
    "\n",
    "# ==================== BATCH PROCESSING ====================\n",
    "def create_all_submissions(language, model_name):\n",
    "    \"\"\"Create clean submissions for all three subtasks\"\"\"\n",
    "    print(f\"Creating clean submission files for {language.upper()} using {model_name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    create_subtask1_submission(language, model_name)\n",
    "    create_subtask2_submission(language, model_name)\n",
    "    create_subtask3_submission(language, model_name)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"All submission files created successfully!\")\n",
    "    print(\"\\nIMPORTANT: These files use the TUNED THRESHOLDS which typically perform better.\")\n",
    "    print(\"If you want to use default threshold (0.5), modify the code to use '_default' columns.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741885d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating submissions for ALL models...\n",
      "\n",
      "================================================================================\n",
      "Creating clean submission files for ENG using twitter-roberta-base-hate-latest\n",
      "================================================================================\n",
      "Subtask 1: Created ./submission/submission_subtask1_eng_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'polarization']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  polarization\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58             0\n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb             0\n",
      "2  eng_95770ff547ea5e48b0be00f385986483             0\n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf             1\n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20             0\n",
      "\n",
      "Subtask 2: Created ./submission/submission_subtask2_eng_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  gender/sexual  political  religious  \\\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58              0          0          0   \n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb              0          0          0   \n",
      "2  eng_95770ff547ea5e48b0be00f385986483              0          0          0   \n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf              0          0          0   \n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20              0          0          0   \n",
      "\n",
      "   racial/ethnic  other  \n",
      "0              0      0  \n",
      "1              0      0  \n",
      "2              0      0  \n",
      "3              0      0  \n",
      "4              0      0  \n",
      "\n",
      "Subtask 3: Created ./submission/submission_subtask3_eng_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  stereotype  vilification  \\\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58           0             0   \n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb           0             0   \n",
      "2  eng_95770ff547ea5e48b0be00f385986483           0             0   \n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf           0             0   \n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20           0             0   \n",
      "\n",
      "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
      "0               0                 0                0             0  \n",
      "1               0                 0                0             0  \n",
      "2               0                 0                0             0  \n",
      "3               1                 1                1             1  \n",
      "4               0                 0                0             0  \n",
      "\n",
      "================================================================================\n",
      "All submission files created successfully!\n",
      "\n",
      "IMPORTANT: These files use the TUNED THRESHOLDS which typically perform better.\n",
      "If you want to use default threshold (0.5), modify the code to use '_default' columns.\n",
      "\n",
      "================================================================================\n",
      "Creating clean submission files for ENG using deberta-v3-base\n",
      "================================================================================\n",
      "Subtask 1: Created ./submission/submission_subtask1_eng_deberta-v3-base.csv\n",
      "  Columns: ['id', 'polarization']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  polarization\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58             0\n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb             0\n",
      "2  eng_95770ff547ea5e48b0be00f385986483             0\n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf             0\n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20             0\n",
      "\n",
      "Subtask 2: Created ./submission/submission_subtask2_eng_deberta-v3-base.csv\n",
      "  Columns: ['id', 'gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  gender/sexual  political  religious  \\\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58              0          0          0   \n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb              0          0          0   \n",
      "2  eng_95770ff547ea5e48b0be00f385986483              0          0          0   \n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf              0          0          0   \n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20              0          0          0   \n",
      "\n",
      "   racial/ethnic  other  \n",
      "0              0      0  \n",
      "1              0      0  \n",
      "2              0      0  \n",
      "3              0      0  \n",
      "4              0      0  \n",
      "\n",
      "Subtask 3: Created ./submission/submission_subtask3_eng_deberta-v3-base.csv\n",
      "  Columns: ['id', 'stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  stereotype  vilification  \\\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58           0             0   \n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb           0             0   \n",
      "2  eng_95770ff547ea5e48b0be00f385986483           0             0   \n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf           0             0   \n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20           0             0   \n",
      "\n",
      "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
      "0               0                 0                0             0  \n",
      "1               0                 0                0             0  \n",
      "2               0                 0                0             0  \n",
      "3               0                 0                0             0  \n",
      "4               0                 0                0             0  \n",
      "\n",
      "================================================================================\n",
      "All submission files created successfully!\n",
      "\n",
      "IMPORTANT: These files use the TUNED THRESHOLDS which typically perform better.\n",
      "If you want to use default threshold (0.5), modify the code to use '_default' columns.\n",
      "\n",
      "================================================================================\n",
      "Creating clean submission files for ENG using xlm-roberta-base\n",
      "================================================================================\n",
      "Subtask 1: Created ./submission/submission_subtask1_eng_xlm-roberta-base.csv\n",
      "  Columns: ['id', 'polarization']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  polarization\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58             0\n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb             0\n",
      "2  eng_95770ff547ea5e48b0be00f385986483             0\n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf             0\n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20             0\n",
      "\n",
      "Subtask 2: Created ./submission/submission_subtask2_eng_xlm-roberta-base.csv\n",
      "  Columns: ['id', 'gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  gender/sexual  political  religious  \\\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58              0          0          0   \n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb              0          0          0   \n",
      "2  eng_95770ff547ea5e48b0be00f385986483              0          0          0   \n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf              0          0          0   \n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20              0          0          0   \n",
      "\n",
      "   racial/ethnic  other  \n",
      "0              0      0  \n",
      "1              0      0  \n",
      "2              0      0  \n",
      "3              0      0  \n",
      "4              0      0  \n",
      "\n",
      "Subtask 3: Created ./submission/submission_subtask3_eng_xlm-roberta-base.csv\n",
      "  Columns: ['id', 'stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
      "  Rows: 160\n",
      "  Sample:\n",
      "                                     id  stereotype  vilification  \\\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58           0             0   \n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb           0             0   \n",
      "2  eng_95770ff547ea5e48b0be00f385986483           0             0   \n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf           0             0   \n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20           0             0   \n",
      "\n",
      "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
      "0               0                 0                0             0  \n",
      "1               0                 0                0             0  \n",
      "2               0                 0                0             0  \n",
      "3               0                 0                0             0  \n",
      "4               0                 0                0             0  \n",
      "\n",
      "================================================================================\n",
      "All submission files created successfully!\n",
      "\n",
      "IMPORTANT: These files use the TUNED THRESHOLDS which typically perform better.\n",
      "If you want to use default threshold (0.5), modify the code to use '_default' columns.\n",
      "\n",
      "================================================================================\n",
      "Creating clean submission files for SWA using twitter-roberta-base-hate-latest\n",
      "================================================================================\n",
      "Subtask 1: Created ./submission/submission_subtask1_swa_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'polarization']\n",
      "  Rows: 349\n",
      "  Sample:\n",
      "                                     id  polarization\n",
      "0  swa_a5748df181277341143f7da4175add4a             1\n",
      "1  swa_2df0d42f9b49ea2e4fb006b2e6604e6d             1\n",
      "2  swa_3718757514005767302b7220b08e409d             1\n",
      "3  swa_9fa3337a35cce723d60c06056d422330             1\n",
      "4  swa_5c39ac8ef70345e9e3c21a47f8769bc0             1\n",
      "\n",
      "Subtask 2: Created ./submission/submission_subtask2_swa_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
      "  Rows: 349\n",
      "  Sample:\n",
      "                                     id  gender/sexual  political  religious  \\\n",
      "0  swa_a5748df181277341143f7da4175add4a              0          0          0   \n",
      "1  swa_2df0d42f9b49ea2e4fb006b2e6604e6d              0          0          0   \n",
      "2  swa_3718757514005767302b7220b08e409d              0          0          0   \n",
      "3  swa_9fa3337a35cce723d60c06056d422330              0          0          0   \n",
      "4  swa_5c39ac8ef70345e9e3c21a47f8769bc0              0          0          0   \n",
      "\n",
      "   racial/ethnic  other  \n",
      "0              1      0  \n",
      "1              1      0  \n",
      "2              1      0  \n",
      "3              1      0  \n",
      "4              1      0  \n",
      "\n",
      "Subtask 3: Created ./submission/submission_subtask3_swa_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
      "  Rows: 349\n",
      "  Sample:\n",
      "                                     id  stereotype  vilification  \\\n",
      "0  swa_a5748df181277341143f7da4175add4a           1             1   \n",
      "1  swa_2df0d42f9b49ea2e4fb006b2e6604e6d           1             1   \n",
      "2  swa_3718757514005767302b7220b08e409d           1             1   \n",
      "3  swa_9fa3337a35cce723d60c06056d422330           1             1   \n",
      "4  swa_5c39ac8ef70345e9e3c21a47f8769bc0           1             1   \n",
      "\n",
      "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
      "0               1                 1                1             1  \n",
      "1               1                 1                1             1  \n",
      "2               0                 1                1             1  \n",
      "3               1                 1                1             1  \n",
      "4               0                 1                1             1  \n",
      "\n",
      "================================================================================\n",
      "All submission files created successfully!\n",
      "\n",
      "IMPORTANT: These files use the TUNED THRESHOLDS which typically perform better.\n",
      "If you want to use default threshold (0.5), modify the code to use '_default' columns.\n",
      "\n",
      "================================================================================\n",
      "Creating clean submission files for AMH using twitter-roberta-base-hate-latest\n",
      "================================================================================\n",
      "Subtask 1: Created ./submission/submission_subtask1_amh_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'polarization']\n",
      "  Rows: 166\n",
      "  Sample:\n",
      "                                     id  polarization\n",
      "0  amh_ca702c5ddc6b46c73576c8f6d3f0c0b6             1\n",
      "1  amh_1fcbc6173a80cddfce64017e171419fd             1\n",
      "2  amh_d9be456f48f7c180812de29d43935f96             1\n",
      "3  amh_1cc5f5cccbb1c98be13832c33a019b39             1\n",
      "4  amh_d19beb623af75470ba7b50f1fbb1144e             1\n",
      "\n",
      "Subtask 2: Created ./submission/submission_subtask2_amh_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
      "  Rows: 166\n",
      "  Sample:\n",
      "                                     id  gender/sexual  political  religious  \\\n",
      "0  amh_ca702c5ddc6b46c73576c8f6d3f0c0b6              1          1          1   \n",
      "1  amh_1fcbc6173a80cddfce64017e171419fd              0          1          1   \n",
      "2  amh_d9be456f48f7c180812de29d43935f96              1          1          1   \n",
      "3  amh_1cc5f5cccbb1c98be13832c33a019b39              1          1          1   \n",
      "4  amh_d19beb623af75470ba7b50f1fbb1144e              1          1          1   \n",
      "\n",
      "   racial/ethnic  other  \n",
      "0              1      1  \n",
      "1              1      1  \n",
      "2              1      1  \n",
      "3              1      1  \n",
      "4              1      1  \n",
      "\n",
      "Subtask 3: Created ./submission/submission_subtask3_amh_twitter-roberta-base-hate-latest.csv\n",
      "  Columns: ['id', 'stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
      "  Rows: 166\n",
      "  Sample:\n",
      "                                     id  stereotype  vilification  \\\n",
      "0  amh_ca702c5ddc6b46c73576c8f6d3f0c0b6           1             1   \n",
      "1  amh_1fcbc6173a80cddfce64017e171419fd           1             1   \n",
      "2  amh_d9be456f48f7c180812de29d43935f96           1             1   \n",
      "3  amh_1cc5f5cccbb1c98be13832c33a019b39           1             1   \n",
      "4  amh_d19beb623af75470ba7b50f1fbb1144e           1             1   \n",
      "\n",
      "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
      "0               0                 1                1             1  \n",
      "1               0                 1                1             1  \n",
      "2               0                 1                1             1  \n",
      "3               0                 1                1             1  \n",
      "4               0                 1                1             1  \n",
      "\n",
      "================================================================================\n",
      "All submission files created successfully!\n",
      "\n",
      "IMPORTANT: These files use the TUNED THRESHOLDS which typically perform better.\n",
      "If you want to use default threshold (0.5), modify the code to use '_default' columns.\n",
      "\n",
      "================================================================================\n",
      "Creating clean submission files for SWA using afro-xlmr-base\n",
      "================================================================================\n",
      "Subtask 1: Created ./submission/submission_subtask1_swa_afro-xlmr-base.csv\n",
      "  Columns: ['id', 'polarization']\n",
      "  Rows: 349\n",
      "  Sample:\n",
      "                                     id  polarization\n",
      "0  swa_a5748df181277341143f7da4175add4a             1\n",
      "1  swa_2df0d42f9b49ea2e4fb006b2e6604e6d             1\n",
      "2  swa_3718757514005767302b7220b08e409d             1\n",
      "3  swa_9fa3337a35cce723d60c06056d422330             1\n",
      "4  swa_5c39ac8ef70345e9e3c21a47f8769bc0             1\n",
      "\n",
      "Subtask 2: Created ./submission/submission_subtask2_swa_afro-xlmr-base.csv\n",
      "  Columns: ['id', 'gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
      "  Rows: 349\n",
      "  Sample:\n",
      "                                     id  gender/sexual  political  religious  \\\n",
      "0  swa_a5748df181277341143f7da4175add4a              0          0          0   \n",
      "1  swa_2df0d42f9b49ea2e4fb006b2e6604e6d              0          0          0   \n",
      "2  swa_3718757514005767302b7220b08e409d              0          0          0   \n",
      "3  swa_9fa3337a35cce723d60c06056d422330              0          0          0   \n",
      "4  swa_5c39ac8ef70345e9e3c21a47f8769bc0              0          0          0   \n",
      "\n",
      "   racial/ethnic  other  \n",
      "0              1      0  \n",
      "1              1      0  \n",
      "2              1      0  \n",
      "3              1      0  \n",
      "4              1      0  \n",
      "\n",
      "Subtask 3: Created ./submission/submission_subtask3_swa_afro-xlmr-base.csv\n",
      "  Columns: ['id', 'stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
      "  Rows: 349\n",
      "  Sample:\n",
      "                                     id  stereotype  vilification  \\\n",
      "0  swa_a5748df181277341143f7da4175add4a           1             1   \n",
      "1  swa_2df0d42f9b49ea2e4fb006b2e6604e6d           1             1   \n",
      "2  swa_3718757514005767302b7220b08e409d           1             1   \n",
      "3  swa_9fa3337a35cce723d60c06056d422330           1             1   \n",
      "4  swa_5c39ac8ef70345e9e3c21a47f8769bc0           1             1   \n",
      "\n",
      "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
      "0               1                 1                1             1  \n",
      "1               1                 1                1             1  \n",
      "2               0                 1                1             1  \n",
      "3               1                 1                1             1  \n",
      "4               0                 0                0             1  \n",
      "\n",
      "================================================================================\n",
      "All submission files created successfully!\n",
      "\n",
      "IMPORTANT: These files use the TUNED THRESHOLDS which typically perform better.\n",
      "If you want to use default threshold (0.5), modify the code to use '_default' columns.\n",
      "\n",
      "================================================================================\n",
      "Creating clean submission files for AMH using afro-xlmr-base\n",
      "================================================================================\n",
      "Subtask 1: Created ./submission/submission_subtask1_amh_afro-xlmr-base.csv\n",
      "  Columns: ['id', 'polarization']\n",
      "  Rows: 166\n",
      "  Sample:\n",
      "                                     id  polarization\n",
      "0  amh_ca702c5ddc6b46c73576c8f6d3f0c0b6             0\n",
      "1  amh_1fcbc6173a80cddfce64017e171419fd             0\n",
      "2  amh_d9be456f48f7c180812de29d43935f96             1\n",
      "3  amh_1cc5f5cccbb1c98be13832c33a019b39             0\n",
      "4  amh_d19beb623af75470ba7b50f1fbb1144e             1\n",
      "\n",
      "Subtask 2: Created ./submission/submission_subtask2_amh_afro-xlmr-base.csv\n",
      "  Columns: ['id', 'gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
      "  Rows: 166\n",
      "  Sample:\n",
      "                                     id  gender/sexual  political  religious  \\\n",
      "0  amh_ca702c5ddc6b46c73576c8f6d3f0c0b6              0          0          0   \n",
      "1  amh_1fcbc6173a80cddfce64017e171419fd              0          0          0   \n",
      "2  amh_d9be456f48f7c180812de29d43935f96              0          1          0   \n",
      "3  amh_1cc5f5cccbb1c98be13832c33a019b39              1          0          0   \n",
      "4  amh_d19beb623af75470ba7b50f1fbb1144e              0          1          0   \n",
      "\n",
      "   racial/ethnic  other  \n",
      "0              0      0  \n",
      "1              0      0  \n",
      "2              1      1  \n",
      "3              0      0  \n",
      "4              1      1  \n",
      "\n",
      "Subtask 3: Created ./submission/submission_subtask3_amh_afro-xlmr-base.csv\n",
      "  Columns: ['id', 'stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
      "  Rows: 166\n",
      "  Sample:\n",
      "                                     id  stereotype  vilification  \\\n",
      "0  amh_ca702c5ddc6b46c73576c8f6d3f0c0b6           0             0   \n",
      "1  amh_1fcbc6173a80cddfce64017e171419fd           0             0   \n",
      "2  amh_d9be456f48f7c180812de29d43935f96           1             1   \n",
      "3  amh_1cc5f5cccbb1c98be13832c33a019b39           0             0   \n",
      "4  amh_d19beb623af75470ba7b50f1fbb1144e           1             0   \n",
      "\n",
      "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
      "0               0                 0                0             0  \n",
      "1               0                 0                0             0  \n",
      "2               0                 1                1             1  \n",
      "3               0                 0                0             0  \n",
      "4               0                 1                1             1  \n",
      "\n",
      "================================================================================\n",
      "All submission files created successfully!\n",
      "\n",
      "IMPORTANT: These files use the TUNED THRESHOLDS which typically perform better.\n",
      "If you want to use default threshold (0.5), modify the code to use '_default' columns.\n"
     ]
    }
   ],
   "source": [
    "# ==================== MAIN ====================\n",
    "if __name__ == \"__main__\":\n",
    "    # Create submissions for the configured language and model\n",
    "    # create_all_submissions(LANGUAGE, MODEL_NAME)\n",
    "    \n",
    "    # Optional: Create submissions for all models\n",
    "    # Uncomment the lines below if you want to create submissions for all trained models\n",
    "    \n",
    "    print(\"\\n\\nCreating submissions for ALL models...\")\n",
    "    models_eng = ['twitter-roberta-base-hate-latest', 'deberta-v3-base', 'xlm-roberta-base']\n",
    "    models_african = ['twitter-roberta-base-hate-latest', 'afro-xlmr-base']\n",
    "    \n",
    "    for model in models_eng:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        create_all_submissions('eng', model)\n",
    "    \n",
    "    for model in models_african:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        create_all_submissions('swa', model)\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        create_all_submissions('amh', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f085928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
