{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "zip_path = \"/content/drive/My Drive/dev_phase.zip\"\n",
        "!unzip \"$zip_path\" -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BHcvBjNLSF5o",
        "outputId": "ffdc6db4-5130-40b6-8bdf-b03af4f6b7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Archive:  /content/drive/My Drive/dev_phase.zip\n",
            "   creating: /content/subtask1/\n",
            "   creating: /content/subtask1/dev/\n",
            "  inflating: /content/subtask1/dev/nep.csv  \n",
            "  inflating: /content/subtask1/dev/ita.csv  \n",
            "  inflating: /content/subtask1/dev/pol.csv  \n",
            "  inflating: /content/subtask1/dev/rus.csv  \n",
            "  inflating: /content/subtask1/dev/tel.csv  \n",
            "  inflating: /content/subtask1/dev/hin.csv  \n",
            "  inflating: /content/subtask1/dev/hau.csv  \n",
            "  inflating: /content/subtask1/dev/pan.csv  \n",
            "  inflating: /content/subtask1/dev/ori.csv  \n",
            "  inflating: /content/subtask1/dev/spa.csv  \n",
            "  inflating: /content/subtask1/dev/deu.csv  \n",
            "  inflating: /content/subtask1/dev/fas.csv  \n",
            "  inflating: /content/subtask1/dev/arb.csv  \n",
            "  inflating: /content/subtask1/dev/ben.csv  \n",
            "  inflating: /content/subtask1/dev/amh.csv  \n",
            "  inflating: /content/subtask1/dev/khm.csv  \n",
            "  inflating: /content/subtask1/dev/tur.csv  \n",
            "  inflating: /content/subtask1/dev/zho.csv  \n",
            "  inflating: /content/subtask1/dev/eng.csv  \n",
            "  inflating: /content/subtask1/dev/swa.csv  \n",
            "  inflating: /content/subtask1/dev/urd.csv  \n",
            "  inflating: /content/subtask1/dev/mya.csv  \n",
            "   creating: /content/subtask1/train/\n",
            "  inflating: /content/subtask1/train/nep.csv  \n",
            "  inflating: /content/subtask1/train/pol.csv  \n",
            "  inflating: /content/subtask1/train/rus.csv  \n",
            "  inflating: /content/subtask1/train/ita.csv  \n",
            "  inflating: /content/subtask1/train/hin.csv  \n",
            "  inflating: /content/subtask1/train/tel.csv  \n",
            "  inflating: /content/subtask1/train/fas.csv  \n",
            "  inflating: /content/subtask1/train/deu.csv  \n",
            "  inflating: /content/subtask1/train/hau.csv  \n",
            "  inflating: /content/subtask1/train/pan.csv  \n",
            "  inflating: /content/subtask1/train/ori.csv  \n",
            "  inflating: /content/subtask1/train/spa.csv  \n",
            "  inflating: /content/subtask1/train/arb.csv  \n",
            "  inflating: /content/subtask1/train/khm.csv  \n",
            "  inflating: /content/subtask1/train/tur.csv  \n",
            "  inflating: /content/subtask1/train/zho.csv  \n",
            "  inflating: /content/subtask1/train/amh.csv  \n",
            "  inflating: /content/subtask1/train/ben.csv  \n",
            "  inflating: /content/subtask1/train/swa.csv  \n",
            "  inflating: /content/subtask1/train/urd.csv  \n",
            "  inflating: /content/subtask1/train/eng.csv  \n",
            "  inflating: /content/subtask1/train/mya.csv  \n",
            "   creating: /content/subtask2/\n",
            "   creating: /content/subtask2/train/\n",
            "  inflating: /content/subtask2/train/nep.csv  \n",
            "  inflating: /content/subtask2/train/ita.csv  \n",
            "  inflating: /content/subtask2/train/rus.csv  \n",
            "  inflating: /content/subtask2/train/pol.csv  \n",
            "  inflating: /content/subtask2/train/hin.csv  \n",
            "  inflating: /content/subtask2/train/tel.csv  \n",
            "  inflating: /content/subtask2/train/deu.csv  \n",
            "  inflating: /content/subtask2/train/fas.csv  \n",
            "  inflating: /content/subtask2/train/pan.csv  \n",
            "  inflating: /content/subtask2/train/hau.csv  \n",
            "  inflating: /content/subtask2/train/spa.csv  \n",
            "  inflating: /content/subtask2/train/ori.csv  \n",
            "  inflating: /content/subtask2/train/arb.csv  \n",
            "  inflating: /content/subtask2/train/amh.csv  \n",
            "  inflating: /content/subtask2/train/zho.csv  \n",
            "  inflating: /content/subtask2/train/tur.csv  \n",
            "  inflating: /content/subtask2/train/khm.csv  \n",
            "  inflating: /content/subtask2/train/ben.csv  \n",
            "  inflating: /content/subtask2/train/swa.csv  \n",
            "  inflating: /content/subtask2/train/urd.csv  \n",
            "  inflating: /content/subtask2/train/eng.csv  \n",
            "  inflating: /content/subtask2/train/mya.csv  \n",
            "   creating: /content/subtask2/dev/\n",
            "  inflating: /content/subtask2/dev/pol.csv  \n",
            "  inflating: /content/subtask2/dev/rus.csv  \n",
            "  inflating: /content/subtask2/dev/ita.csv  \n",
            "  inflating: /content/subtask2/dev/nep.csv  \n",
            "  inflating: /content/subtask2/dev/fas.csv  \n",
            "  inflating: /content/subtask2/dev/deu.csv  \n",
            "  inflating: /content/subtask2/dev/spa.csv  \n",
            "  inflating: /content/subtask2/dev/ori.csv  \n",
            "  inflating: /content/subtask2/dev/pan.csv  \n",
            "  inflating: /content/subtask2/dev/hau.csv  \n",
            "  inflating: /content/subtask2/dev/hin.csv  \n",
            "  inflating: /content/subtask2/dev/tel.csv  \n",
            "  inflating: /content/subtask2/dev/tur.csv  \n",
            "  inflating: /content/subtask2/dev/zho.csv  \n",
            "  inflating: /content/subtask2/dev/khm.csv  \n",
            "  inflating: /content/subtask2/dev/amh.csv  \n",
            "  inflating: /content/subtask2/dev/ben.csv  \n",
            "  inflating: /content/subtask2/dev/arb.csv  \n",
            "  inflating: /content/subtask2/dev/mya.csv  \n",
            "  inflating: /content/subtask2/dev/urd.csv  \n",
            "  inflating: /content/subtask2/dev/swa.csv  \n",
            "  inflating: /content/subtask2/dev/eng.csv  \n",
            "   creating: /content/subtask3/\n",
            "   creating: /content/subtask3/dev/\n",
            "  inflating: /content/subtask3/dev/eng.csv  \n",
            "  inflating: /content/subtask3/dev/urd.csv  \n",
            "  inflating: /content/subtask3/dev/swa.csv  \n",
            "  inflating: /content/subtask3/dev/arb.csv  \n",
            "  inflating: /content/subtask3/dev/ben.csv  \n",
            "  inflating: /content/subtask3/dev/amh.csv  \n",
            "  inflating: /content/subtask3/dev/tur.csv  \n",
            "  inflating: /content/subtask3/dev/zho.csv  \n",
            "  inflating: /content/subtask3/dev/khm.csv  \n",
            "  inflating: /content/subtask3/dev/tel.csv  \n",
            "  inflating: /content/subtask3/dev/hin.csv  \n",
            "  inflating: /content/subtask3/dev/spa.csv  \n",
            "  inflating: /content/subtask3/dev/ori.csv  \n",
            "  inflating: /content/subtask3/dev/pan.csv  \n",
            "  inflating: /content/subtask3/dev/hau.csv  \n",
            "  inflating: /content/subtask3/dev/deu.csv  \n",
            "  inflating: /content/subtask3/dev/fas.csv  \n",
            "  inflating: /content/subtask3/dev/nep.csv  \n",
            "   creating: /content/subtask3/train/\n",
            "  inflating: /content/subtask3/train/amh.csv  \n",
            "  inflating: /content/subtask3/train/zho.csv  \n",
            "  inflating: /content/subtask3/train/tur.csv  \n",
            "  inflating: /content/subtask3/train/khm.csv  \n",
            "  inflating: /content/subtask3/train/ben.csv  \n",
            "  inflating: /content/subtask3/train/arb.csv  \n",
            "  inflating: /content/subtask3/train/swa.csv  \n",
            "  inflating: /content/subtask3/train/urd.csv  \n",
            "  inflating: /content/subtask3/train/eng.csv  \n",
            "  inflating: /content/subtask3/train/nep.csv  \n",
            "  inflating: /content/subtask3/train/deu.csv  \n",
            "  inflating: /content/subtask3/train/fas.csv  \n",
            "  inflating: /content/subtask3/train/pan.csv  \n",
            "  inflating: /content/subtask3/train/hau.csv  \n",
            "  inflating: /content/subtask3/train/spa.csv  \n",
            "  inflating: /content/subtask3/train/ori.csv  \n",
            "  inflating: /content/subtask3/train/hin.csv  \n",
            "  inflating: /content/subtask3/train/tel.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from torch.utils.data import Dataset\n",
        "import wandb\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Disable wandb\n",
        "wandb.init(mode=\"disabled\")\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "1AmN1xFhk2Tp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "acced1d4-4f56-44b4-a81b-36de59114765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LANGUAGE = 'swa'  # Change to 'swa' or 'amh'\n",
        "\n",
        "LABEL_ORDER = ['gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'eng': [\n",
        "        'cardiffnlp/twitter-roberta-base-hate-latest',\n",
        "        'microsoft/deberta-v3-base',\n",
        "        'FacebookAI/xlm-roberta-base'\n",
        "    ],\n",
        "    'swa': [\n",
        "        'cardiffnlp/twitter-roberta-base-hate-latest',\n",
        "        'Davlan/afro-xlmr-base'\n",
        "    ],\n",
        "    'amh': [\n",
        "        'cardiffnlp/twitter-roberta-base-hate-latest',\n",
        "        'Davlan/afro-xlmr-base'\n",
        "    ]\n",
        "}\n",
        "\n",
        "NUM_EPOCHS = 8\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 3e-5\n",
        "MAX_LENGTH = 256\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "RESULTS_CSV = 'results_subtask2_simple.csv'\n",
        "PREDICTIONS_DIR = 'predictions_subtask2_simple'"
      ],
      "metadata": {
        "id": "qV7tuo5wj4gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelAwareDeberta(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom model for multi-label classification\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name, num_labels=5, dropout_rate=0.2):\n",
        "        super(LabelAwareDeberta, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.deberta = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.deberta.config.hidden_size\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        nn.init.zeros_(self.classifier.bias)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights if hasattr(self, 'pos_weights') else None)\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}\n",
        "\n",
        "class PolarizationDatasetWithHints(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset with instruction prefix\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.instruction = \"Classify text for polarizing content related to: \" + \", \".join(LABEL_ORDER) + \". Text: \"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        full_text = self.instruction + text\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            full_text,\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "def compute_metrics_multilabel(p):\n",
        "    \"\"\"Compute macro and per-class F1 scores\"\"\"\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "\n",
        "    macro_f1 = f1_score(p.label_ids, preds, average='macro', zero_division=0)\n",
        "    per_class_f1 = f1_score(p.label_ids, preds, average=None, zero_division=0)\n",
        "\n",
        "    print(f\"\\n  Per-class F1: {dict(zip(LABEL_ORDER, [f'{x:.3f}' for x in per_class_f1]))}\")\n",
        "\n",
        "    return {'f1_macro': macro_f1}\n",
        "\n",
        "\n",
        "def train_and_evaluate_model(model_name, language, X_train, y_train, X_val, y_val, X_test, test_df, pos_weights):\n",
        "    \"\"\"\n",
        "    Train and evaluate a single model\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Training: {model_name} on {language.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    train_dataset = PolarizationDatasetWithHints(X_train.tolist(), y_train.tolist(), tokenizer, MAX_LENGTH)\n",
        "    val_dataset = PolarizationDatasetWithHints(X_val.tolist(), y_val.tolist(), tokenizer, MAX_LENGTH)\n",
        "\n",
        "    model = LabelAwareDeberta(\n",
        "        model_name=model_name,\n",
        "        num_labels=len(LABEL_ORDER),\n",
        "        dropout_rate=DROPOUT_RATE\n",
        "    ).to(device)\n",
        "\n",
        "    model.pos_weights = pos_weights\n",
        "\n",
        "    # Training arguments\n",
        "    total_steps = (len(train_dataset) // BATCH_SIZE) * NUM_EPOCHS\n",
        "    warmup_steps = int(0.1 * total_steps)\n",
        "\n",
        "    model_short_name = model_name.split('/')[-1]\n",
        "    output_dir = f\"./output_{language}_{model_short_name}_subtask2\"\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=NUM_EPOCHS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        weight_decay=0.01,\n",
        "        warmup_steps=warmup_steps,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        logging_steps=50,\n",
        "        logging_first_step=True,\n",
        "        report_to=\"none\",\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics_multilabel,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    print(f\"\\nStarting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    print(f\"\\nEvaluating on validation set...\")\n",
        "    val_results = trainer.evaluate(val_dataset)\n",
        "\n",
        "    print(f\"\\nValidation Results:\")\n",
        "    print(f\"   Macro F1: {val_results['eval_f1_macro']:.4f}\")\n",
        "\n",
        "    print(f\"\\nGenerating predictions on test set...\")\n",
        "\n",
        "    if set(LABEL_ORDER).issubset(test_df.columns):\n",
        "        test_df[LABEL_ORDER] = test_df[LABEL_ORDER].fillna(0)\n",
        "        test_labels = test_df[LABEL_ORDER].values.tolist()\n",
        "    else:\n",
        "        print(\"Label columns not found in test set. Using dummy labels.\")\n",
        "        test_labels = np.zeros((len(test_df), len(LABEL_ORDER))).tolist()\n",
        "\n",
        "    test_dataset = PolarizationDatasetWithHints(test_df['text'].tolist(), test_labels, tokenizer, MAX_LENGTH)\n",
        "\n",
        "    trainer.compute_metrics = None\n",
        "    prediction_output = trainer.predict(test_dataset)\n",
        "\n",
        "    logits = torch.tensor(prediction_output.predictions)\n",
        "    probs = torch.sigmoid(logits)\n",
        "    predictions = (probs > 0.5).int().numpy()\n",
        "\n",
        "    print(f\"\\nPrediction Distribution:\")\n",
        "    for i, label in enumerate(LABEL_ORDER):\n",
        "        count = predictions[:, i].sum()\n",
        "        print(f\"   {label:20s}: {count} ({count/len(predictions)*100:.1f}%)\")\n",
        "\n",
        "    training_time = (datetime.now() - start_time).total_seconds() / 60\n",
        "    print(f\"\\nTraining time: {training_time:.2f} minutes\")\n",
        "\n",
        "    os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
        "\n",
        "    submission_df = pd.DataFrame(predictions, columns=LABEL_ORDER)\n",
        "\n",
        "    if 'id' in test_df.columns:\n",
        "        submission_df.insert(0, 'id', test_df['id'])\n",
        "    elif 'ID' in test_df.columns:\n",
        "        submission_df.insert(0, 'id', test_df['ID'])\n",
        "\n",
        "    pred_filename = f\"{PREDICTIONS_DIR}/predictions_{language}_{model_short_name}.csv\"\n",
        "    submission_df.to_csv(pred_filename, index=False)\n",
        "    print(f\"\\nPredictions saved to {pred_filename}\")\n",
        "\n",
        "    # Compile results\n",
        "    results = {\n",
        "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'model_name': model_name,\n",
        "        'model_short_name': model_short_name,\n",
        "        'language': language,\n",
        "        'train_samples': len(X_train),\n",
        "        'val_samples': len(X_val),\n",
        "        'test_samples': len(X_test),\n",
        "        'val_f1_macro': val_results['eval_f1_macro'],\n",
        "        'training_time_minutes': training_time\n",
        "    }\n",
        "\n",
        "    # Add per-class predictions\n",
        "    for i, label in enumerate(LABEL_ORDER):\n",
        "        results[f'pred_{label}'] = int(predictions[:, i].sum())\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "OlqdU83AkCDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MULTI-LABEL POLARIZATION CLASSIFICATION - SUBTASK 2\")\n",
        "    print(f\"Language: {LANGUAGE.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Load data\n",
        "    print(f\"\\nLoading data for {LANGUAGE}...\")\n",
        "    train_path = f'./subtask2/train/{LANGUAGE}.csv'\n",
        "    dev_path = f'./subtask2/dev/{LANGUAGE}.csv'\n",
        "\n",
        "    try:\n",
        "        train_full = pd.read_csv(train_path)\n",
        "        test_df = pd.read_csv(dev_path)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return\n",
        "\n",
        "    X = train_full['text'].values\n",
        "    y = train_full[LABEL_ORDER].values\n",
        "\n",
        "    print(f\"\\nCalculating class weights...\")\n",
        "    pos_counts = train_full[LABEL_ORDER].sum().values\n",
        "    num_samples = len(train_full)\n",
        "    neg_counts = num_samples - pos_counts\n",
        "\n",
        "    pos_weights = np.where(pos_counts > 0, neg_counts / pos_counts, 1.0)\n",
        "    pos_weights = torch.tensor(pos_weights, dtype=torch.float).to(device)\n",
        "\n",
        "    print(f\"   Label distribution:\")\n",
        "    for i, col in enumerate(LABEL_ORDER):\n",
        "        print(f\"      {col:20s}: {int(pos_counts[i])} positive ({pos_counts[i]/num_samples*100:.1f}%) - weight: {pos_weights[i]:.2f}\")\n",
        "    print(f\"\\nCreating train/val split...\")\n",
        "    label_sums = y.sum(axis=0)\n",
        "    primary_label_idx = np.argmax(label_sums)\n",
        "    primary_labels = y[:, primary_label_idx]\n",
        "\n",
        "    unique, counts = np.unique(primary_labels, return_counts=True)\n",
        "    if np.min(counts) >= 2:\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=primary_labels\n",
        "        )\n",
        "        print(f\"   Stratified split on '{LABEL_ORDER[primary_label_idx]}'\")\n",
        "    else:\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        print(f\"   Random split (stratification not possible)\")\n",
        "\n",
        "    print(f\"   Train: {len(X_train)}, Val: {len(X_val)}\")\n",
        "\n",
        "    X_test = test_df['text'].values\n",
        "\n",
        "    models_to_test = MODELS_CONFIG.get(LANGUAGE, [])\n",
        "    if not models_to_test:\n",
        "        print(f\"No models configured for language: {LANGUAGE}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nModels to test: {len(models_to_test)}\")\n",
        "    for i, model in enumerate(models_to_test, 1):\n",
        "        print(f\"   {i}. {model}\")\n",
        "\n",
        "    all_results = []\n",
        "    for model_name in models_to_test:\n",
        "        try:\n",
        "            results = train_and_evaluate_model(\n",
        "                model_name, LANGUAGE,\n",
        "                X_train, y_train,\n",
        "                X_val, y_val,\n",
        "                X_test,\n",
        "                test_df,\n",
        "                pos_weights\n",
        "            )\n",
        "            all_results.append(results)\n",
        "\n",
        "            results_df = pd.DataFrame(all_results)\n",
        "\n",
        "            if os.path.exists(RESULTS_CSV):\n",
        "                existing_df = pd.read_csv(RESULTS_CSV)\n",
        "                results_df = pd.concat([existing_df, results_df], ignore_index=True)\n",
        "\n",
        "            results_df.to_csv(RESULTS_CSV, index=False)\n",
        "            print(f\"\\nResults updated in {RESULTS_CSV}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError training {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TRAINING COMPLETE\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"\\nSuccessfully trained {len(all_results)} out of {len(models_to_test)} models\")\n",
        "    print(f\"Results saved to: {RESULTS_CSV}\")\n",
        "    print(f\"Predictions saved to: {PREDICTIONS_DIR}/\")\n",
        "\n",
        "    if all_results:\n",
        "        print(f\"\\nBest Model (by Validation Macro F1):\")\n",
        "        best_model = max(all_results, key=lambda x: x['val_f1_macro'])\n",
        "        print(f\"   Model: {best_model['model_short_name']}\")\n",
        "        print(f\"   Val Macro F1: {best_model['val_f1_macro']:.4f}\")\n",
        "        print(f\"   Training Time: {best_model['training_time_minutes']:.1f} min\")\n"
      ],
      "metadata": {
        "id": "H1Yp1S5nkiy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MwISnYhUkj2P",
        "outputId": "4d439683-03e9-4172-d82e-aca61637f9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "MULTI-LABEL POLARIZATION CLASSIFICATION - SUBTASK 2\n",
            "Language: SWA\n",
            "================================================================================\n",
            "\n",
            "Loading data for swa...\n",
            "\n",
            "Calculating class weights...\n",
            "   Label distribution:\n",
            "      gender/sexual       : 156 positive (2.2%) - weight: 43.81\n",
            "      political           : 186 positive (2.7%) - weight: 36.59\n",
            "      religious           : 247 positive (3.5%) - weight: 27.30\n",
            "      racial/ethnic       : 2483 positive (35.5%) - weight: 1.82\n",
            "      other               : 555 positive (7.9%) - weight: 11.60\n",
            "\n",
            "Creating train/val split...\n",
            "   Stratified split on 'racial/ethnic'\n",
            "   Train: 5592, Val: 1399\n",
            "\n",
            "Models to test: 2\n",
            "   1. cardiffnlp/twitter-roberta-base-hate-latest\n",
            "   2. Davlan/afro-xlmr-base\n",
            "\n",
            "================================================================================\n",
            "Training: cardiffnlp/twitter-roberta-base-hate-latest on SWA\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-hate-latest and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2800' max='2800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2800/2800 16:05, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.291900</td>\n",
              "      <td>1.230787</td>\n",
              "      <td>0.318155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.087500</td>\n",
              "      <td>1.164500</td>\n",
              "      <td>0.403319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.953500</td>\n",
              "      <td>1.039917</td>\n",
              "      <td>0.449533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.849500</td>\n",
              "      <td>0.974735</td>\n",
              "      <td>0.406313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.893800</td>\n",
              "      <td>1.184267</td>\n",
              "      <td>0.441543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.542300</td>\n",
              "      <td>1.773170</td>\n",
              "      <td>0.518381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.522200</td>\n",
              "      <td>1.772285</td>\n",
              "      <td>0.470428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.484000</td>\n",
              "      <td>1.910242</td>\n",
              "      <td>0.491322</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Per-class F1: {'gender/sexual': '0.000', 'political': '0.229', 'religious': '0.698', 'racial/ethnic': '0.664', 'other': '0.000'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.000', 'political': '0.353', 'religious': '0.865', 'racial/ethnic': '0.739', 'other': '0.060'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.097', 'political': '0.333', 'religious': '0.841', 'racial/ethnic': '0.728', 'other': '0.248'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.156', 'political': '0.163', 'religious': '0.644', 'racial/ethnic': '0.755', 'other': '0.313'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.124', 'political': '0.216', 'religious': '0.807', 'racial/ethnic': '0.756', 'other': '0.305'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.248', 'political': '0.416', 'religious': '0.876', 'racial/ethnic': '0.744', 'other': '0.309'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.238', 'political': '0.319', 'religious': '0.748', 'racial/ethnic': '0.733', 'other': '0.315'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.273', 'political': '0.333', 'religious': '0.780', 'racial/ethnic': '0.746', 'other': '0.325'}\n",
            "\n",
            "Evaluating on validation set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Per-class F1: {'gender/sexual': '0.248', 'political': '0.416', 'religious': '0.876', 'racial/ethnic': '0.744', 'other': '0.309'}\n",
            "\n",
            "Validation Results:\n",
            "   Macro F1: 0.5184\n",
            "\n",
            "Generating predictions on test set...\n",
            "\n",
            "Prediction Distribution:\n",
            "   gender/sexual       : 18 (5.2%)\n",
            "   political           : 11 (3.2%)\n",
            "   religious           : 13 (3.7%)\n",
            "   racial/ethnic       : 143 (41.0%)\n",
            "   other               : 42 (12.0%)\n",
            "\n",
            "Training time: 16.33 minutes\n",
            "\n",
            "Predictions saved to predictions_subtask2_simple/predictions_swa_twitter-roberta-base-hate-latest.csv\n",
            "\n",
            "Results updated in results_subtask2_simple.csv\n",
            "\n",
            "================================================================================\n",
            "Training: Davlan/afro-xlmr-base on SWA\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2800' max='2800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2800/2800 22:05, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.402000</td>\n",
              "      <td>1.117366</td>\n",
              "      <td>0.403280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.967100</td>\n",
              "      <td>1.118938</td>\n",
              "      <td>0.445639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.788700</td>\n",
              "      <td>1.059054</td>\n",
              "      <td>0.486392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.655100</td>\n",
              "      <td>1.012074</td>\n",
              "      <td>0.455211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.710100</td>\n",
              "      <td>1.269283</td>\n",
              "      <td>0.482165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.401900</td>\n",
              "      <td>1.794320</td>\n",
              "      <td>0.532885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.327400</td>\n",
              "      <td>1.780744</td>\n",
              "      <td>0.518326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.239300</td>\n",
              "      <td>1.887171</td>\n",
              "      <td>0.522191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Per-class F1: {'gender/sexual': '0.296', 'political': '0.151', 'religious': '0.812', 'racial/ethnic': '0.757', 'other': '0.000'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.240', 'political': '0.224', 'religious': '0.832', 'racial/ethnic': '0.747', 'other': '0.186'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.145', 'political': '0.404', 'religious': '0.847', 'racial/ethnic': '0.774', 'other': '0.261'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.190', 'political': '0.250', 'religious': '0.774', 'racial/ethnic': '0.770', 'other': '0.292'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.229', 'political': '0.329', 'religious': '0.786', 'racial/ethnic': '0.750', 'other': '0.317'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.275', 'political': '0.429', 'religious': '0.844', 'racial/ethnic': '0.773', 'other': '0.344'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.250', 'political': '0.457', 'religious': '0.786', 'racial/ethnic': '0.758', 'other': '0.341'}\n",
            "\n",
            "  Per-class F1: {'gender/sexual': '0.253', 'political': '0.404', 'religious': '0.825', 'racial/ethnic': '0.770', 'other': '0.360'}\n",
            "\n",
            "Evaluating on validation set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Per-class F1: {'gender/sexual': '0.275', 'political': '0.429', 'religious': '0.844', 'racial/ethnic': '0.773', 'other': '0.344'}\n",
            "\n",
            "Validation Results:\n",
            "   Macro F1: 0.5329\n",
            "\n",
            "Generating predictions on test set...\n",
            "\n",
            "Prediction Distribution:\n",
            "   gender/sexual       : 7 (2.0%)\n",
            "   political           : 16 (4.6%)\n",
            "   religious           : 13 (3.7%)\n",
            "   racial/ethnic       : 134 (38.4%)\n",
            "   other               : 37 (10.6%)\n",
            "\n",
            "Training time: 22.37 minutes\n",
            "\n",
            "Predictions saved to predictions_subtask2_simple/predictions_swa_afro-xlmr-base.csv\n",
            "\n",
            "Results updated in results_subtask2_simple.csv\n",
            "\n",
            "================================================================================\n",
            "TRAINING COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Successfully trained 2 out of 2 models\n",
            "Results saved to: results_subtask2_simple.csv\n",
            "Predictions saved to: predictions_subtask2_simple/\n",
            "\n",
            "Best Model (by Validation Macro F1):\n",
            "   Model: afro-xlmr-base\n",
            "   Val Macro F1: 0.5329\n",
            "   Training Time: 22.4 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello\")"
      ],
      "metadata": {
        "id": "8NMISuJ1kyxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1697496a-dcaa-404a-d215-acdda3cbad10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L9Lj3egVskWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}