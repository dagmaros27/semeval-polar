{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xqKx94ad44ph",
        "outputId": "c9ee589e-6704-4f21-9bda-bf216419d193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Archive:  /content/drive/My Drive/dev_phase.zip\n",
            "   creating: /content/subtask1/\n",
            "   creating: /content/subtask1/dev/\n",
            "  inflating: /content/subtask1/dev/nep.csv  \n",
            "  inflating: /content/subtask1/dev/ita.csv  \n",
            "  inflating: /content/subtask1/dev/pol.csv  \n",
            "  inflating: /content/subtask1/dev/rus.csv  \n",
            "  inflating: /content/subtask1/dev/tel.csv  \n",
            "  inflating: /content/subtask1/dev/hin.csv  \n",
            "  inflating: /content/subtask1/dev/hau.csv  \n",
            "  inflating: /content/subtask1/dev/pan.csv  \n",
            "  inflating: /content/subtask1/dev/ori.csv  \n",
            "  inflating: /content/subtask1/dev/spa.csv  \n",
            "  inflating: /content/subtask1/dev/deu.csv  \n",
            "  inflating: /content/subtask1/dev/fas.csv  \n",
            "  inflating: /content/subtask1/dev/arb.csv  \n",
            "  inflating: /content/subtask1/dev/ben.csv  \n",
            "  inflating: /content/subtask1/dev/amh.csv  \n",
            "  inflating: /content/subtask1/dev/khm.csv  \n",
            "  inflating: /content/subtask1/dev/tur.csv  \n",
            "  inflating: /content/subtask1/dev/zho.csv  \n",
            "  inflating: /content/subtask1/dev/eng.csv  \n",
            "  inflating: /content/subtask1/dev/swa.csv  \n",
            "  inflating: /content/subtask1/dev/urd.csv  \n",
            "  inflating: /content/subtask1/dev/mya.csv  \n",
            "   creating: /content/subtask1/train/\n",
            "  inflating: /content/subtask1/train/nep.csv  \n",
            "  inflating: /content/subtask1/train/pol.csv  \n",
            "  inflating: /content/subtask1/train/rus.csv  \n",
            "  inflating: /content/subtask1/train/ita.csv  \n",
            "  inflating: /content/subtask1/train/hin.csv  \n",
            "  inflating: /content/subtask1/train/tel.csv  \n",
            "  inflating: /content/subtask1/train/fas.csv  \n",
            "  inflating: /content/subtask1/train/deu.csv  \n",
            "  inflating: /content/subtask1/train/hau.csv  \n",
            "  inflating: /content/subtask1/train/pan.csv  \n",
            "  inflating: /content/subtask1/train/ori.csv  \n",
            "  inflating: /content/subtask1/train/spa.csv  \n",
            "  inflating: /content/subtask1/train/arb.csv  \n",
            "  inflating: /content/subtask1/train/khm.csv  \n",
            "  inflating: /content/subtask1/train/tur.csv  \n",
            "  inflating: /content/subtask1/train/zho.csv  \n",
            "  inflating: /content/subtask1/train/amh.csv  \n",
            "  inflating: /content/subtask1/train/ben.csv  \n",
            "  inflating: /content/subtask1/train/swa.csv  \n",
            "  inflating: /content/subtask1/train/urd.csv  \n",
            "  inflating: /content/subtask1/train/eng.csv  \n",
            "  inflating: /content/subtask1/train/mya.csv  \n",
            "   creating: /content/subtask2/\n",
            "   creating: /content/subtask2/train/\n",
            "  inflating: /content/subtask2/train/nep.csv  \n",
            "  inflating: /content/subtask2/train/ita.csv  \n",
            "  inflating: /content/subtask2/train/rus.csv  \n",
            "  inflating: /content/subtask2/train/pol.csv  \n",
            "  inflating: /content/subtask2/train/hin.csv  \n",
            "  inflating: /content/subtask2/train/tel.csv  \n",
            "  inflating: /content/subtask2/train/deu.csv  \n",
            "  inflating: /content/subtask2/train/fas.csv  \n",
            "  inflating: /content/subtask2/train/pan.csv  \n",
            "  inflating: /content/subtask2/train/hau.csv  \n",
            "  inflating: /content/subtask2/train/spa.csv  \n",
            "  inflating: /content/subtask2/train/ori.csv  \n",
            "  inflating: /content/subtask2/train/arb.csv  \n",
            "  inflating: /content/subtask2/train/amh.csv  \n",
            "  inflating: /content/subtask2/train/zho.csv  \n",
            "  inflating: /content/subtask2/train/tur.csv  \n",
            "  inflating: /content/subtask2/train/khm.csv  \n",
            "  inflating: /content/subtask2/train/ben.csv  \n",
            "  inflating: /content/subtask2/train/swa.csv  \n",
            "  inflating: /content/subtask2/train/urd.csv  \n",
            "  inflating: /content/subtask2/train/eng.csv  \n",
            "  inflating: /content/subtask2/train/mya.csv  \n",
            "   creating: /content/subtask2/dev/\n",
            "  inflating: /content/subtask2/dev/pol.csv  \n",
            "  inflating: /content/subtask2/dev/rus.csv  \n",
            "  inflating: /content/subtask2/dev/ita.csv  \n",
            "  inflating: /content/subtask2/dev/nep.csv  \n",
            "  inflating: /content/subtask2/dev/fas.csv  \n",
            "  inflating: /content/subtask2/dev/deu.csv  \n",
            "  inflating: /content/subtask2/dev/spa.csv  \n",
            "  inflating: /content/subtask2/dev/ori.csv  \n",
            "  inflating: /content/subtask2/dev/pan.csv  \n",
            "  inflating: /content/subtask2/dev/hau.csv  \n",
            "  inflating: /content/subtask2/dev/hin.csv  \n",
            "  inflating: /content/subtask2/dev/tel.csv  \n",
            "  inflating: /content/subtask2/dev/tur.csv  \n",
            "  inflating: /content/subtask2/dev/zho.csv  \n",
            "  inflating: /content/subtask2/dev/khm.csv  \n",
            "  inflating: /content/subtask2/dev/amh.csv  \n",
            "  inflating: /content/subtask2/dev/ben.csv  \n",
            "  inflating: /content/subtask2/dev/arb.csv  \n",
            "  inflating: /content/subtask2/dev/mya.csv  \n",
            "  inflating: /content/subtask2/dev/urd.csv  \n",
            "  inflating: /content/subtask2/dev/swa.csv  \n",
            "  inflating: /content/subtask2/dev/eng.csv  \n",
            "   creating: /content/subtask3/\n",
            "   creating: /content/subtask3/dev/\n",
            "  inflating: /content/subtask3/dev/eng.csv  \n",
            "  inflating: /content/subtask3/dev/urd.csv  \n",
            "  inflating: /content/subtask3/dev/swa.csv  \n",
            "  inflating: /content/subtask3/dev/arb.csv  \n",
            "  inflating: /content/subtask3/dev/ben.csv  \n",
            "  inflating: /content/subtask3/dev/amh.csv  \n",
            "  inflating: /content/subtask3/dev/tur.csv  \n",
            "  inflating: /content/subtask3/dev/zho.csv  \n",
            "  inflating: /content/subtask3/dev/khm.csv  \n",
            "  inflating: /content/subtask3/dev/tel.csv  \n",
            "  inflating: /content/subtask3/dev/hin.csv  \n",
            "  inflating: /content/subtask3/dev/spa.csv  \n",
            "  inflating: /content/subtask3/dev/ori.csv  \n",
            "  inflating: /content/subtask3/dev/pan.csv  \n",
            "  inflating: /content/subtask3/dev/hau.csv  \n",
            "  inflating: /content/subtask3/dev/deu.csv  \n",
            "  inflating: /content/subtask3/dev/fas.csv  \n",
            "  inflating: /content/subtask3/dev/nep.csv  \n",
            "   creating: /content/subtask3/train/\n",
            "  inflating: /content/subtask3/train/amh.csv  \n",
            "  inflating: /content/subtask3/train/zho.csv  \n",
            "  inflating: /content/subtask3/train/tur.csv  \n",
            "  inflating: /content/subtask3/train/khm.csv  \n",
            "  inflating: /content/subtask3/train/ben.csv  \n",
            "  inflating: /content/subtask3/train/arb.csv  \n",
            "  inflating: /content/subtask3/train/swa.csv  \n",
            "  inflating: /content/subtask3/train/urd.csv  \n",
            "  inflating: /content/subtask3/train/eng.csv  \n",
            "  inflating: /content/subtask3/train/nep.csv  \n",
            "  inflating: /content/subtask3/train/deu.csv  \n",
            "  inflating: /content/subtask3/train/fas.csv  \n",
            "  inflating: /content/subtask3/train/pan.csv  \n",
            "  inflating: /content/subtask3/train/hau.csv  \n",
            "  inflating: /content/subtask3/train/spa.csv  \n",
            "  inflating: /content/subtask3/train/ori.csv  \n",
            "  inflating: /content/subtask3/train/hin.csv  \n",
            "  inflating: /content/subtask3/train/tel.csv  \n"
          ]
        }
      ],
      "source": [
        "# Only if using colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "zip_path = \"/content/drive/My Drive/dev_phase.zip\"\n",
        "!unzip \"$zip_path\" -d /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ReDqWEj8pxT5",
        "outputId": "365445f1-925e-410f-b210-1d15f64e2784"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from torch.utils.data import Dataset\n",
        "import wandb\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Disable wandb\n",
        "wandb.init(mode=\"disabled\")\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGs2Bbocwdp-"
      },
      "outputs": [],
      "source": [
        "LANGUAGE = 'swa'  # Change to 'eng', 'swa' or 'amh'\n",
        "\n",
        "LABEL_ORDER = ['stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'eng': [\n",
        "        'cardiffnlp/twitter-roberta-base-hate-latest',\n",
        "        'microsoft/deberta-v3-base',\n",
        "        'FacebookAI/xlm-roberta-base'\n",
        "    ],\n",
        "    'swa': [\n",
        "        'cardiffnlp/twitter-roberta-base-hate-latest',\n",
        "        'Davlan/afro-xlmr-base'\n",
        "    ],\n",
        "    'amh': [\n",
        "        'cardiffnlp/twitter-roberta-base-hate-latest',\n",
        "        'Davlan/afro-xlmr-base'\n",
        "    ]\n",
        "}\n",
        "\n",
        "NUM_EPOCHS = 8\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 3e-5\n",
        "MAX_LENGTH = 256\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "RESULTS_CSV = 'results_subtask3_simple.csv'\n",
        "PREDICTIONS_DIR = 'predictions_subtask3_simple'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kSbujikDjNy"
      },
      "outputs": [],
      "source": [
        "class ManifestationClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom model for manifestation identification\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name, num_labels=6, dropout_rate=0.2):\n",
        "        super(ManifestationClassifier, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        # Load base model\n",
        "        self.deberta = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.deberta.config.hidden_size\n",
        "\n",
        "        # Simple classifier\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        # Initialize weights\n",
        "        nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        nn.init.zeros_(self.classifier.bias)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights if hasattr(self, 'pos_weights') else None)\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}\n",
        "\n",
        "# ==================== DATASET ====================\n",
        "class ManifestationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset with task-specific instruction\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.instruction = \"Identify polarization manifestations: \" + \", \".join(LABEL_ORDER) + \". Text: \"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        full_text = self.instruction + text\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            full_text,\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ==================== METRICS ====================\n",
        "def compute_metrics_multilabel(p):\n",
        "    \"\"\"Compute macro and per-class F1 scores\"\"\"\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "\n",
        "    macro_f1 = f1_score(p.label_ids, preds, average='macro', zero_division=0)\n",
        "    per_class_f1 = f1_score(p.label_ids, preds, average=None, zero_division=0)\n",
        "\n",
        "    print(f\"\\n  Per-class F1: {dict(zip(LABEL_ORDER, [f'{x:.3f}' for x in per_class_f1]))}\")\n",
        "\n",
        "    return {'f1_macro': macro_f1}\n",
        "\n",
        "# ==================== TRAIN AND EVALUATE MODEL ====================\n",
        "def train_and_evaluate_model(model_name, language, X_train, y_train, X_val, y_val, X_test, test_df, pos_weights):\n",
        "    \"\"\"\n",
        "    Train and evaluate a single model\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Training: {model_name} on {language.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    # Initialize tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = ManifestationDataset(X_train.tolist(), y_train.tolist(), tokenizer, MAX_LENGTH)\n",
        "    val_dataset = ManifestationDataset(X_val.tolist(), y_val.tolist(), tokenizer, MAX_LENGTH)\n",
        "\n",
        "    # Initialize model\n",
        "    model = ManifestationClassifier(\n",
        "        model_name=model_name,\n",
        "        num_labels=len(LABEL_ORDER),\n",
        "        dropout_rate=DROPOUT_RATE\n",
        "    ).to(device)\n",
        "\n",
        "    model.pos_weights = pos_weights\n",
        "\n",
        "    # Training arguments\n",
        "    total_steps = (len(train_dataset) // BATCH_SIZE) * NUM_EPOCHS\n",
        "    warmup_steps = int(0.1 * total_steps)\n",
        "\n",
        "    model_short_name = model_name.split('/')[-1]\n",
        "    output_dir = f\"./output_{language}_{model_short_name}_subtask3\"\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=NUM_EPOCHS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        weight_decay=0.01,\n",
        "        warmup_steps=warmup_steps,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        logging_steps=50,\n",
        "        logging_first_step=True,\n",
        "        report_to=\"none\",\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics_multilabel,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    print(f\"\\nStarting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    print(f\"\\nEvaluating on validation set...\")\n",
        "    val_results = trainer.evaluate(val_dataset)\n",
        "\n",
        "    print(f\"\\nValidation Results:\")\n",
        "    print(f\"   Macro F1: {val_results['eval_f1_macro']:.4f}\")\n",
        "\n",
        "    # Predict on test set\n",
        "    print(f\"\\nGenerating predictions on test set...\")\n",
        "\n",
        "    # Handle test labels\n",
        "    if set(LABEL_ORDER).issubset(test_df.columns):\n",
        "        test_df[LABEL_ORDER] = test_df[LABEL_ORDER].fillna(0)\n",
        "        test_labels = test_df[LABEL_ORDER].values.tolist()\n",
        "    else:\n",
        "        print(\"Label columns not found in test set. Using dummy labels.\")\n",
        "        test_labels = np.zeros((len(test_df), len(LABEL_ORDER))).tolist()\n",
        "\n",
        "    test_dataset = ManifestationDataset(test_df['text'].tolist(), test_labels, tokenizer, MAX_LENGTH)\n",
        "\n",
        "    # Disable metrics for prediction\n",
        "    trainer.compute_metrics = None\n",
        "    prediction_output = trainer.predict(test_dataset)\n",
        "\n",
        "    # Convert to binary predictions\n",
        "    logits = torch.tensor(prediction_output.predictions)\n",
        "    probs = torch.sigmoid(logits)\n",
        "    predictions = (probs > 0.5).int().numpy()\n",
        "\n",
        "    # Print distribution\n",
        "    print(f\"\\nPrediction Distribution:\")\n",
        "    for i, label in enumerate(LABEL_ORDER):\n",
        "        count = predictions[:, i].sum()\n",
        "        print(f\"   {label:20s}: {count} ({count/len(predictions)*100:.1f}%)\")\n",
        "\n",
        "    training_time = (datetime.now() - start_time).total_seconds() / 60\n",
        "    print(f\"\\nTraining time: {training_time:.2f} minutes\")\n",
        "\n",
        "    # Save predictions\n",
        "    os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
        "\n",
        "    submission_df = pd.DataFrame(predictions, columns=LABEL_ORDER)\n",
        "\n",
        "    if 'id' in test_df.columns:\n",
        "        submission_df.insert(0, 'id', test_df['id'])\n",
        "    elif 'ID' in test_df.columns:\n",
        "        submission_df.insert(0, 'id', test_df['ID'])\n",
        "\n",
        "    pred_filename = f\"{PREDICTIONS_DIR}/predictions_{language}_{model_short_name}.csv\"\n",
        "    submission_df.to_csv(pred_filename, index=False)\n",
        "    print(f\"\\nPredictions saved to {pred_filename}\")\n",
        "\n",
        "    # Compile results\n",
        "    results = {\n",
        "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'model_name': model_name,\n",
        "        'model_short_name': model_short_name,\n",
        "        'language': language,\n",
        "        'train_samples': len(X_train),\n",
        "        'val_samples': len(X_val),\n",
        "        'test_samples': len(X_test),\n",
        "        'val_f1_macro': val_results['eval_f1_macro'],\n",
        "        'training_time_minutes': training_time\n",
        "    }\n",
        "\n",
        "    # Add per-class predictions\n",
        "    for i, label in enumerate(LABEL_ORDER):\n",
        "        results[f'pred_{label}'] = int(predictions[:, i].sum())\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvzoqeY5DtK6"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MANIFESTATION CLASSIFICATION - SUBTASK 3\")\n",
        "    print(f\"Language: {LANGUAGE.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Load data\n",
        "    print(f\"\\nLoading data for {LANGUAGE}...\")\n",
        "    train_path = f'./subtask3/train/{LANGUAGE}.csv'\n",
        "    dev_path = f'./subtask3/dev/{LANGUAGE}.csv'\n",
        "\n",
        "    try:\n",
        "        train_full = pd.read_csv(train_path)\n",
        "        test_df = pd.read_csv(dev_path)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return\n",
        "\n",
        "    # Extract features and labels\n",
        "    X = train_full['text'].values\n",
        "    y = train_full[LABEL_ORDER].values\n",
        "\n",
        "    # Calculate pos_weights\n",
        "    print(f\"\\nCalculating class weights...\")\n",
        "    pos_counts = train_full[LABEL_ORDER].sum().values\n",
        "    num_samples = len(train_full)\n",
        "    neg_counts = num_samples - pos_counts\n",
        "\n",
        "    pos_weights = np.where(pos_counts > 0, neg_counts / pos_counts, 1.0)\n",
        "    pos_weights = torch.tensor(pos_weights, dtype=torch.float).to(device)\n",
        "\n",
        "    print(f\"   Label distribution:\")\n",
        "    for i, col in enumerate(LABEL_ORDER):\n",
        "        print(f\"      {col:20s}: {int(pos_counts[i])} positive ({pos_counts[i]/num_samples*100:.1f}%) - weight: {pos_weights[i]:.2f}\")\n",
        "\n",
        "    # Train/val split\n",
        "    print(f\"\\nCreating train/val split...\")\n",
        "    label_sums = y.sum(axis=0)\n",
        "    primary_label_idx = np.argmax(label_sums)\n",
        "    primary_labels = y[:, primary_label_idx]\n",
        "\n",
        "    unique, counts = np.unique(primary_labels, return_counts=True)\n",
        "    if np.min(counts) >= 2:\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=primary_labels\n",
        "        )\n",
        "        print(f\"   Stratified split on '{LABEL_ORDER[primary_label_idx]}'\")\n",
        "    else:\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        print(f\"   Random split (stratification not possible)\")\n",
        "\n",
        "    print(f\"   Train: {len(X_train)}, Val: {len(X_val)}\")\n",
        "\n",
        "    X_test = test_df['text'].values\n",
        "\n",
        "    # Get models for this language\n",
        "    models_to_test = MODELS_CONFIG.get(LANGUAGE, [])\n",
        "    if not models_to_test:\n",
        "        print(f\"No models configured for language: {LANGUAGE}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nModels to test: {len(models_to_test)}\")\n",
        "    for i, model in enumerate(models_to_test, 1):\n",
        "        print(f\"   {i}. {model}\")\n",
        "\n",
        "    # Train all models\n",
        "    all_results = []\n",
        "    for model_name in models_to_test:\n",
        "        try:\n",
        "            results = train_and_evaluate_model(\n",
        "                model_name, LANGUAGE,\n",
        "                X_train, y_train,\n",
        "                X_val, y_val,\n",
        "                X_test,\n",
        "                test_df,\n",
        "                pos_weights\n",
        "            )\n",
        "            all_results.append(results)\n",
        "\n",
        "            # Save results after each model\n",
        "            results_df = pd.DataFrame(all_results)\n",
        "\n",
        "            if os.path.exists(RESULTS_CSV):\n",
        "                existing_df = pd.read_csv(RESULTS_CSV)\n",
        "                results_df = pd.concat([existing_df, results_df], ignore_index=True)\n",
        "\n",
        "            results_df.to_csv(RESULTS_CSV, index=False)\n",
        "            print(f\"\\nResults updated in {RESULTS_CSV}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError training {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TRAINING COMPLETE\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"\\nSuccessfully trained {len(all_results)} out of {len(models_to_test)} models\")\n",
        "    print(f\"Results saved to: {RESULTS_CSV}\")\n",
        "    print(f\"Predictions saved to: {PREDICTIONS_DIR}/\")\n",
        "\n",
        "    if all_results:\n",
        "        print(f\"\\nBest Model (by Validation Macro F1):\")\n",
        "        best_model = max(all_results, key=lambda x: x['val_f1_macro'])\n",
        "        print(f\"   Model: {best_model['model_short_name']}\")\n",
        "        print(f\"   Val Macro F1: {best_model['val_f1_macro']:.4f}\")\n",
        "        print(f\"   Training Time: {best_model['training_time_minutes']:.1f} min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cCTAySwcDxLs",
        "outputId": "0558a010-7d64-4a15-b27f-0be67d6e57a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "MANIFESTATION CLASSIFICATION - SUBTASK 3\n",
            "Language: SWA\n",
            "================================================================================\n",
            "\n",
            "Loading data for swa...\n",
            "\n",
            "Calculating class weights...\n",
            "   Label distribution:\n",
            "      stereotype          : 2775 positive (39.7%) - weight: 1.52\n",
            "      vilification        : 2883 positive (41.2%) - weight: 1.42\n",
            "      dehumanization      : 893 positive (12.8%) - weight: 6.83\n",
            "      extreme_language    : 1673 positive (23.9%) - weight: 3.18\n",
            "      lack_of_empathy     : 2080 positive (29.8%) - weight: 2.36\n",
            "      invalidation        : 1637 positive (23.4%) - weight: 3.27\n",
            "\n",
            "Creating train/val split...\n",
            "   Stratified split on 'vilification'\n",
            "   Train: 5592, Val: 1399\n",
            "\n",
            "Models to test: 2\n",
            "   1. cardiffnlp/twitter-roberta-base-hate-latest\n",
            "   2. Davlan/afro-xlmr-base\n",
            "\n",
            "================================================================================\n",
            "Training: cardiffnlp/twitter-roberta-base-hate-latest on SWA\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-hate-latest and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2800' max='2800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2800/2800 17:18, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.930800</td>\n",
              "      <td>0.886150</td>\n",
              "      <td>0.510872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.865100</td>\n",
              "      <td>0.831958</td>\n",
              "      <td>0.554195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.818800</td>\n",
              "      <td>0.821776</td>\n",
              "      <td>0.558768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.788300</td>\n",
              "      <td>0.852088</td>\n",
              "      <td>0.561213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.709400</td>\n",
              "      <td>0.926818</td>\n",
              "      <td>0.549465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.647400</td>\n",
              "      <td>1.003363</td>\n",
              "      <td>0.554712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.548300</td>\n",
              "      <td>1.059301</td>\n",
              "      <td>0.563871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.556700</td>\n",
              "      <td>1.106340</td>\n",
              "      <td>0.564276</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Per-class F1: {'stereotype': '0.675', 'vilification': '0.659', 'dehumanization': '0.253', 'extreme_language': '0.429', 'lack_of_empathy': '0.544', 'invalidation': '0.504'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.695', 'vilification': '0.694', 'dehumanization': '0.307', 'extreme_language': '0.492', 'lack_of_empathy': '0.596', 'invalidation': '0.541'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.727', 'vilification': '0.705', 'dehumanization': '0.301', 'extreme_language': '0.489', 'lack_of_empathy': '0.608', 'invalidation': '0.523'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.722', 'vilification': '0.693', 'dehumanization': '0.303', 'extreme_language': '0.505', 'lack_of_empathy': '0.602', 'invalidation': '0.543'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.720', 'vilification': '0.681', 'dehumanization': '0.309', 'extreme_language': '0.479', 'lack_of_empathy': '0.581', 'invalidation': '0.526'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.717', 'vilification': '0.696', 'dehumanization': '0.266', 'extreme_language': '0.500', 'lack_of_empathy': '0.610', 'invalidation': '0.539'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.727', 'vilification': '0.702', 'dehumanization': '0.290', 'extreme_language': '0.499', 'lack_of_empathy': '0.615', 'invalidation': '0.549'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.727', 'vilification': '0.701', 'dehumanization': '0.302', 'extreme_language': '0.492', 'lack_of_empathy': '0.613', 'invalidation': '0.550'}\n",
            "\n",
            "Evaluating on validation set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Per-class F1: {'stereotype': '0.727', 'vilification': '0.701', 'dehumanization': '0.302', 'extreme_language': '0.492', 'lack_of_empathy': '0.613', 'invalidation': '0.550'}\n",
            "\n",
            "Validation Results:\n",
            "   Macro F1: 0.5643\n",
            "\n",
            "Generating predictions on test set...\n",
            "\n",
            "Prediction Distribution:\n",
            "   stereotype          : 187 (53.6%)\n",
            "   vilification        : 179 (51.3%)\n",
            "   dehumanization      : 121 (34.7%)\n",
            "   extreme_language    : 153 (43.8%)\n",
            "   lack_of_empathy     : 169 (48.4%)\n",
            "   invalidation        : 160 (45.8%)\n",
            "\n",
            "Training time: 17.56 minutes\n",
            "\n",
            "Predictions saved to predictions_subtask3_simple/predictions_swa_twitter-roberta-base-hate-latest.csv\n",
            "\n",
            "Results updated in results_subtask3_simple.csv\n",
            "\n",
            "================================================================================\n",
            "Training: Davlan/afro-xlmr-base on SWA\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2800' max='2800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2800/2800 25:42, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.955000</td>\n",
              "      <td>0.890266</td>\n",
              "      <td>0.505058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.813100</td>\n",
              "      <td>0.820050</td>\n",
              "      <td>0.540572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.756000</td>\n",
              "      <td>0.824564</td>\n",
              "      <td>0.564171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.732400</td>\n",
              "      <td>0.827669</td>\n",
              "      <td>0.584409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.600300</td>\n",
              "      <td>0.963477</td>\n",
              "      <td>0.573645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.548500</td>\n",
              "      <td>0.965549</td>\n",
              "      <td>0.578483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.474900</td>\n",
              "      <td>0.997974</td>\n",
              "      <td>0.582080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.502100</td>\n",
              "      <td>1.067570</td>\n",
              "      <td>0.578747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Per-class F1: {'stereotype': '0.707', 'vilification': '0.640', 'dehumanization': '0.237', 'extreme_language': '0.419', 'lack_of_empathy': '0.522', 'invalidation': '0.506'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.708', 'vilification': '0.699', 'dehumanization': '0.281', 'extreme_language': '0.460', 'lack_of_empathy': '0.593', 'invalidation': '0.503'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.738', 'vilification': '0.714', 'dehumanization': '0.307', 'extreme_language': '0.490', 'lack_of_empathy': '0.609', 'invalidation': '0.527'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.746', 'vilification': '0.715', 'dehumanization': '0.346', 'extreme_language': '0.520', 'lack_of_empathy': '0.620', 'invalidation': '0.559'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.719', 'vilification': '0.711', 'dehumanization': '0.324', 'extreme_language': '0.515', 'lack_of_empathy': '0.627', 'invalidation': '0.546'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.729', 'vilification': '0.713', 'dehumanization': '0.337', 'extreme_language': '0.515', 'lack_of_empathy': '0.625', 'invalidation': '0.551'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.729', 'vilification': '0.725', 'dehumanization': '0.341', 'extreme_language': '0.508', 'lack_of_empathy': '0.628', 'invalidation': '0.562'}\n",
            "\n",
            "  Per-class F1: {'stereotype': '0.727', 'vilification': '0.716', 'dehumanization': '0.327', 'extreme_language': '0.519', 'lack_of_empathy': '0.621', 'invalidation': '0.562'}\n",
            "\n",
            "Evaluating on validation set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Per-class F1: {'stereotype': '0.746', 'vilification': '0.715', 'dehumanization': '0.346', 'extreme_language': '0.520', 'lack_of_empathy': '0.620', 'invalidation': '0.559'}\n",
            "\n",
            "Validation Results:\n",
            "   Macro F1: 0.5844\n",
            "\n",
            "Generating predictions on test set...\n",
            "\n",
            "Prediction Distribution:\n",
            "   stereotype          : 153 (43.8%)\n",
            "   vilification        : 164 (47.0%)\n",
            "   dehumanization      : 150 (43.0%)\n",
            "   extreme_language    : 166 (47.6%)\n",
            "   lack_of_empathy     : 163 (46.7%)\n",
            "   invalidation        : 167 (47.9%)\n",
            "\n",
            "Training time: 26.01 minutes\n",
            "\n",
            "Predictions saved to predictions_subtask3_simple/predictions_swa_afro-xlmr-base.csv\n",
            "\n",
            "Results updated in results_subtask3_simple.csv\n",
            "\n",
            "================================================================================\n",
            "TRAINING COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Successfully trained 2 out of 2 models\n",
            "Results saved to: results_subtask3_simple.csv\n",
            "Predictions saved to: predictions_subtask3_simple/\n",
            "\n",
            "Best Model (by Validation Macro F1):\n",
            "   Model: afro-xlmr-base\n",
            "   Val Macro F1: 0.5844\n",
            "   Training Time: 26.0 min\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrFDz2xVEIvN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
